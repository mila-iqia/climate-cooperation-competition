{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2022, salesforce.com, inc and MILA.  \n",
    "All rights reserved.  \n",
    "SPDX-License-Identifier: BSD-3-Clause  \n",
    "For full license text, see the LICENSE file in the repo root  \n",
    "or https://opensource.org/licenses/BSD-3-Clause  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2022, salesforce.com, inc and MILA.  \n",
    "All rights reserved.  \n",
    "SPDX-License-Identifier: BSD-3-Clause  \n",
    "For full license text, see the LICENSE file in the repo root  \n",
    "or https://opensource.org/licenses/BSD-3-Clause  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the notebook to create the datasets and yaml file\n",
    "Dependency: wbgapi, pandas, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T13:38:48.755024Z",
     "start_time": "2022-06-20T13:38:41.305030Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install wbgapi\n",
    "import wbgapi as wb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from opt_helper import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T13:38:48.955369Z",
     "start_time": "2022-06-20T13:38:48.883898Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get convergence population predicted by United Nation\n",
    "lasdf = pd.read_csv(\"csv_asset/UN-pop-pred.csv\")\n",
    "lasdf = lasdf[lasdf[\"Year\"]==2100].reset_index(drop=True)\n",
    "\n",
    "# Get the country classes information from the world bank classification. Class 0 includes countries all over the world. Class 1 to 20 are divided by region X income level.\n",
    "cc = pd.read_csv(\"csv_asset/CountryClass_3.csv\")\n",
    "countryclass = {i:list(cc[cc[\"RIG\"]==i][\"Code\"]) for i in range(1,4)}\n",
    "countryclass[0] = sum([countryclass[i] for i in range(1,4)] ,[])\n",
    "\n",
    "# Get the env protection proportion contribution from the IMF data\n",
    "envdf = pd.read_csv(\"csv_asset/Environmental_Protection_Expenditures_Geo_Avg_Recent_Years_Sum.csv\")\n",
    "\n",
    "# Include the env protection expenditure for the countries\n",
    "import csv\n",
    "env_pay = {}\n",
    "with open(\"csv_asset/Environmental_Protection_Expenditures_Geo_Avg_Recent_Years_Sum.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if row[0] != \"ISO3\":\n",
    "            env_pay[row[0]] = float(row[1])/100\n",
    "\n",
    "# include tax rate\n",
    "taxdf = pd.read_csv(\"csv_asset/tax_rate.csv\")\n",
    "\n",
    "# The series (token) what we are interested.\n",
    "# the list of series that we want to query\n",
    "series_list = [\"NY.GDP.MKTP.CD\",\"CM.MKT.LCAP.CD\", \"SP.POP.TOTL\",\"EN.ATM.CO2E.KT\", \"NE.CON.TOTL.ZS\"]\n",
    "df = wb.data.DataFrame(series_list, time=range(1960, 2022, 1), labels=True)\n",
    "df = df.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Preprocess the data\n",
    "Determine which years are interested and what countries should be excluded (because of lacking in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T13:41:20.877725Z",
     "start_time": "2022-06-20T13:41:20.864791Z"
    }
   },
   "outputs": [],
   "source": [
    "# retrive country codes stuff and make sure the data are float rather than str\n",
    "economy_list = list(df[\"economy\"])[:len(set(df[\"economy\"]))]\n",
    "country_list = list(df[\"Country\"])[:len(set(df[\"economy\"]))]\n",
    "economy_region_list = []\n",
    "for x in economy_list:\n",
    "    if x==\"WLD\": break\n",
    "    else: economy_region_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T13:41:29.002601Z",
     "start_time": "2022-06-20T13:41:20.912271Z"
    }
   },
   "outputs": [],
   "source": [
    "# add to the exec_code list because no GDP data available\n",
    "noY=[]\n",
    "for x in economy_region_list:\n",
    "    tmp = []\n",
    "    for y in range(2003, 2021):\n",
    "        if pd.isnull(get_data_list(df, x, \"Y\")[1][\"YR\"+str(y)]):\n",
    "            tmp.append(0)\n",
    "        else:\n",
    "            tmp.append(1)\n",
    "    if sum(tmp)!=len(range(2003, 2021)):\n",
    "        noY.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEM',\n",
       " 'VEN',\n",
       " 'MAF',\n",
       " 'SSD',\n",
       " 'SOM',\n",
       " 'SXM',\n",
       " 'NRU',\n",
       " 'XKX',\n",
       " 'PRK',\n",
       " 'GIB',\n",
       " 'ERI',\n",
       " 'CUW',\n",
       " 'CHI',\n",
       " 'CYM',\n",
       " 'VGB']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T13:41:29.049095Z",
     "start_time": "2022-06-20T13:41:29.005595Z"
    }
   },
   "outputs": [],
   "source": [
    "# exc_code = noY\n",
    "exc_code = ['YEM','VIR','VEN', 'TKM','SYR', 'MAF', 'SSD', 'SOM', 'SXM', 'SMR', 'MNP', 'NCL', 'NRU', 'LIE', 'XKX', 'PRK', 'IMN', \n",
    "             'GRL', 'GIB', 'PYF', 'FRO', 'ERI', 'CUW', 'CHI', 'CYM', 'VGB', 'ABW', 'AND', \"TWN\"] # exclude codes becasue we don't even have GDP data ever\n",
    "dict_country = {}\n",
    "for i in range(len(economy_list)):\n",
    "    dict_country[economy_list[i]]=country_list[i]\n",
    "years = list(df.columns)[4:]\n",
    "df[years] = df[years].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing the carbon intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:18.676076Z",
     "start_time": "2022-05-24T13:51:14.705700Z"
    }
   },
   "outputs": [],
   "source": [
    "# include the carbon intensity\n",
    "for i in range(len(country_list)):\n",
    "    s = df[df[\"economy\"]==economy_list[i]][df[\"series\"]==\"EN.ATM.CO2E.KT\"][years].reset_index(drop=True)*1_000_000/df[df[\"economy\"]==economy_list[i]][df[\"series\"]==\"NY.GDP.MKTP.CD\"][years].reset_index(drop=True)\n",
    "    s.at[0,\"economy\"] = economy_list[i]\n",
    "    s.at[0,\"Country\"] = country_list[i]\n",
    "    s.at[0,\"series\"] = \"EN.ATM.CO2E.KD.CD\"\n",
    "    s.at[0, \"Series\"] = \"sigma\"\n",
    "    df = df.append(s)\n",
    "    df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:19.181076Z",
     "start_time": "2022-05-24T13:51:18.679081Z"
    }
   },
   "outputs": [],
   "source": [
    "# check those regions who does not have sigma data\n",
    "count = 0\n",
    "noco2 = {}\n",
    "hasco2 = {}\n",
    "for i in range(len(country_list)):\n",
    "    if df[df[\"series\"]==\"EN.ATM.CO2E.KD.CD\"][df[\"economy\"]==economy_list[i]][\"YR2018\"].isnull().values[0]:\n",
    "        noco2[economy_list[i]]=country_list[i]\n",
    "        continue\n",
    "    else:\n",
    "        hasco2[economy_list[i]]=country_list[i]\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:19.197124Z",
     "start_time": "2022-05-24T13:51:19.184074Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the country list without co2 data\n",
    "noco2_region_dict = {}\n",
    "for k,v in noco2.items():\n",
    "    if k==\"WLD\": break\n",
    "    else: noco2_region_dict[k]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:19.212122Z",
     "start_time": "2022-05-24T13:51:19.202121Z"
    }
   },
   "outputs": [],
   "source": [
    "# since there is no co2 data for the key countries, \n",
    "# we manually find a replacement data for them from other countires\n",
    "borrowdict = {'PSE': 'EGY',\n",
    " 'VIR': 'USA',\n",
    " 'VEN': 'MEX',\n",
    " 'TCA': 'GBR',\n",
    " 'MAF': 'FRA',\n",
    " 'SSD': 'EGY',\n",
    " 'SXM': 'NLD',\n",
    " 'SMR': 'ITA',\n",
    " 'PRI': 'USA',\n",
    " 'MNP': 'USA',\n",
    " 'NCL': 'FRA',\n",
    " 'MCO': 'FRA',\n",
    " 'MAC': 'CHN',\n",
    " 'XKX': 'TUR',\n",
    " 'PRK': \"RUS\",\n",
    " 'IMN': 'GBR',\n",
    " 'HKG': 'CHN',\n",
    " 'GUM': 'USA',\n",
    " 'GRL': 'DNK',\n",
    " 'GIB': 'GBR',\n",
    " 'PYF': 'FRA',\n",
    " 'FRO': 'DNK',\n",
    " 'ERI': 'EGY',\n",
    " 'CUW': 'NLD',\n",
    " 'CHI': 'GBR',\n",
    " 'CYM': 'GBR',\n",
    " 'VGB': 'GBR',\n",
    " 'BMU': 'CAN',\n",
    " 'ABW': 'MEX',\n",
    " 'ASM': 'USA',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:19.273117Z",
     "start_time": "2022-05-24T13:51:19.217122Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the country code to index mapping for noco2data available countries\n",
    "code2idx = {}\n",
    "for k in noco2_region_dict.keys():\n",
    "    code2idx[k] = df[df[\"series\"]==\"EN.ATM.CO2E.KD.CD\"][df[\"economy\"]==k].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:19.718638Z",
     "start_time": "2022-05-24T13:51:19.275119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INX\n"
     ]
    }
   ],
   "source": [
    "# update the co2 data for noco2 recorded countries by borrowdict\n",
    "for k in noco2_region_dict.keys(): # borrowdict\n",
    "    try:\n",
    "        df.loc[code2idx[k],years] = df[df[\"series\"]==\"EN.ATM.CO2E.KD.CD\"][df[\"economy\"]==borrowdict[k]][years].iloc[0]\n",
    "    except:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fillna for countries without capital data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:19.733743Z",
     "start_time": "2022-05-24T13:51:19.721641Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the (Y,L) data and predict K data by KNN\n",
    "def get_Y_K_L_pairs(codes, year=None, exc_code=[]):\n",
    "    if year is None:\n",
    "        year = \"YR2020\"\n",
    "    else:\n",
    "        year = \"YR\"+str(year)\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    train_codes = []\n",
    "    test_data = []\n",
    "    test_codes = []\n",
    "    codes_ = []\n",
    "    for code in codes:\n",
    "        if code in exc_code:\n",
    "            continue\n",
    "        else:\n",
    "            label = get_data_list(df, code, \"K\")[1][year]\n",
    "            if pd.isnull(label):\n",
    "                test_data.append([get_data_list(df, code, \"Y\")[1][year], get_data_list(df, code, \"L\")[1][year]])\n",
    "                test_codes.append(code)\n",
    "            else:\n",
    "                train_data.append([get_data_list(df, code, \"Y\")[1][year], get_data_list(df, code, \"L\")[1][year]])\n",
    "                train_label.append(label)\n",
    "                train_codes.append(code)\n",
    "    return np.array(train_data), np.array(train_label), np.array(test_data), dict(zip(train_codes, train_data)), dict(zip(test_codes, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:52.236323Z",
     "start_time": "2022-05-24T13:51:19.736164Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use KNN to predict those who has Y, L data but don't have K data\n",
    "for y in range(2003, 2021):\n",
    "    train_data, train_label, test_data, train_dict, test_dict = get_Y_K_L_pairs(economy_region_list, y, exc_code)\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "    neigh.fit(train_data, train_label)\n",
    "    test_K = neigh.predict(test_data)\n",
    "    test_region = list(test_dict.keys())\n",
    "    for i in range(len(test_region)):\n",
    "        idx = df[df[\"economy\"]==test_region[i]][df[\"series\"]==\"CM.MKT.LCAP.CD\"][\"YR2003\"].index.values[0]\n",
    "        df.loc[idx,\"YR\"+str(y)]=test_K[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use KNN to fill consumption data， prepare the (Y,L) data and predict C data by KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Y_C_L_pairs(codes, year=None, exc_code=[]):\n",
    "    if year is None:\n",
    "        year = \"YR2020\"\n",
    "    else:\n",
    "        year = \"YR\"+str(year)\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    train_codes = []\n",
    "    test_data = []\n",
    "    test_codes = []\n",
    "    codes_ = []\n",
    "    for code in codes:\n",
    "        if code in exc_code:\n",
    "            continue\n",
    "        else:\n",
    "            label = get_data_list(df, code, \"C\")[1][year]\n",
    "            if pd.isnull(label):\n",
    "                test_data.append([get_data_list(df, code, \"Y\")[1][year], get_data_list(df, code, \"L\")[1][year]])\n",
    "                test_codes.append(code)\n",
    "            else:\n",
    "                train_data.append([get_data_list(df, code, \"Y\")[1][year], get_data_list(df, code, \"L\")[1][year]])\n",
    "                train_label.append(label)\n",
    "                train_codes.append(code)\n",
    "    return np.array(train_data), np.array(train_label), np.array(test_data), dict(zip(train_codes, train_data)), dict(zip(test_codes, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use KNN to predict those who has Y, L data but don't have K data\n",
    "for y in range(2003, 2021):\n",
    "    train_data, train_label, test_data, train_dict, test_dict = get_Y_C_L_pairs(economy_region_list, y, exc_code)\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "    neigh.fit(train_data, train_label)\n",
    "    test_C = neigh.predict(test_data)\n",
    "    test_region = list(test_dict.keys())\n",
    "    for i in range(len(test_region)):\n",
    "        idx = df[df[\"economy\"]==test_region[i]][df[\"series\"]==\"NE.CON.TOTL.ZS\"][\"YR2003\"].index.values[0]\n",
    "        df.loc[idx,\"YR\"+str(y)]=test_C[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in economy_region_list:\n",
    "    if code in exc_code:\n",
    "        continue\n",
    "    else:\n",
    "        if len(get_data_list(df, code, \"C\")[0]) == 0:\n",
    "            print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "introduce the tech factor (ATFP) based on Y,K,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:56.578066Z",
     "start_time": "2022-05-24T13:51:52.240330Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(economy_list)):\n",
    "    if economy_list[i] in exc_code: continue\n",
    "    else:\n",
    "        s = df[df[\"economy\"]==economy_list[i]][df[\"series\"]==\"NY.GDP.MKTP.CD\"][years].reset_index(drop=True)/(1000_000_000_000*((df[df[\"economy\"]==economy_list[i]][df[\"series\"]==\"CM.MKT.LCAP.CD\"][years].reset_index(drop=True)/1000_000_000_000)**0.3*(df[df[\"economy\"]==economy_list[i]][df[\"series\"]==\"SP.POP.TOTL\"][years].reset_index(drop=True)/1000_000_000)**0.7))\n",
    "        s.at[0,\"economy\"] = economy_list[i]\n",
    "        s.at[0,\"Country\"] = country_list[i]\n",
    "        s.at[0,\"series\"] = \"ATFP\"\n",
    "        s.at[0, \"Series\"] = \"A\"\n",
    "        df = df.append(s)\n",
    "        df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the results of the time series accross different regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:58.650991Z",
     "start_time": "2022-05-24T13:51:56.580580Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_results = {}\n",
    "for x in economy_region_list:\n",
    "    if x in exc_code:\n",
    "        continue\n",
    "    else:\n",
    "        raw_results[x]={}\n",
    "        raw_results[x][\"TS_Y\"] = get_data_list(df, x, \"Y\")\n",
    "        raw_results[x][\"TS_A\"] = get_data_list(df, x, \"A\")\n",
    "        raw_results[x][\"TS_K\"] = get_data_list(df, x, \"K\")\n",
    "        raw_results[x][\"TS_L\"] = get_data_list(df, x, \"L\")\n",
    "        raw_results[x][\"TS_sigma\"] = get_data_list(df, x, \"sigma\")\n",
    "        raw_results[x][\"TS_C\"] = get_data_list(df, x, \"C\")\n",
    "        raw_results[x][\"La\"] = list(lasdf[lasdf[\"Code\"]==x][\"Population (future projections)\"])[0]\n",
    "        raw_results[x][\"mitigation\"] = get_env_data_list(envdf, x)\n",
    "        raw_results[x][\"saving\"] = 1 - int(raw_results[x][\"TS_C\"][0][-1])/100\n",
    "        try:\n",
    "            raw_results[x][\"tax\"] = get_tax_data_list(taxdf, x)\n",
    "        except:\n",
    "            raw_results[x][\"tax\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'YR1960': 59716249310.9742,\n",
       " 'YR1961': 50056685957.359,\n",
       " 'YR1962': 47209186415.3555,\n",
       " 'YR1963': 50706614526.1472,\n",
       " 'YR1964': 59708125203.8643,\n",
       " 'YR1965': 70436008642.4251,\n",
       " 'YR1966': 76720005491.8964,\n",
       " 'YR1967': 72881364882.4909,\n",
       " 'YR1968': 70846276051.4727,\n",
       " 'YR1969': 79705614854.7674,\n",
       " 'YR1970': 92602634891.6589,\n",
       " 'YR1971': 99800593790.9886,\n",
       " 'YR1972': 113689308020.343,\n",
       " 'YR1973': 138543170458.064,\n",
       " 'YR1974': 144188970821.072,\n",
       " 'YR1975': 163429530659.638,\n",
       " 'YR1976': 153939265947.775,\n",
       " 'YR1977': 174935933078.663,\n",
       " 'YR1978': 218502169137.562,\n",
       " 'YR1979': 263711728825.005,\n",
       " 'YR1980': 306165314855.846,\n",
       " 'YR1981': 289576581830.449,\n",
       " 'YR1982': 283928672988.111,\n",
       " 'YR1983': 304748904221.289,\n",
       " 'YR1984': 313728547706.897,\n",
       " 'YR1985': 309835803013.587,\n",
       " 'YR1986': 300514204520.969,\n",
       " 'YR1987': 327089403146.073,\n",
       " 'YR1988': 407844670393.058,\n",
       " 'YR1989': 456289122063.159,\n",
       " 'YR1990': 394565747349.055,\n",
       " 'YR1991': 413375445354.473,\n",
       " 'YR1992': 493136961883.002,\n",
       " 'YR1993': 619111946511.628,\n",
       " 'YR1994': 564321854521.013,\n",
       " 'YR1995': 734484834573.582,\n",
       " 'YR1996': 863749314718.538,\n",
       " 'YR1997': 961601980984.623,\n",
       " 'YR1998': 1029060747620.65,\n",
       " 'YR1999': 1094010482677.39,\n",
       " 'YR2000': 1211331651829.85,\n",
       " 'YR2001': 1339400897153.44,\n",
       " 'YR2002': 1470557654824.11,\n",
       " 'YR2003': 1660280543870.95,\n",
       " 'YR2004': 1955346768757.64,\n",
       " 'YR2005': 2285961149904.26,\n",
       " 'YR2006': 2752118657221.64,\n",
       " 'YR2007': 3550327803024.69,\n",
       " 'YR2008': 4594336785752.06,\n",
       " 'YR2009': 5101691124358.41,\n",
       " 'YR2010': 6087191746738.57,\n",
       " 'YR2011': 7551545703518.14,\n",
       " 'YR2012': 8532185381696.43,\n",
       " 'YR2013': 9570471111847.82,\n",
       " 'YR2014': 10475624944290.1,\n",
       " 'YR2015': 11061572618594.8,\n",
       " 'YR2016': 11233313730288.5,\n",
       " 'YR2017': 12310491333980.9,\n",
       " 'YR2018': 13894907857925.9,\n",
       " 'YR2019': 14279968506242.8,\n",
       " 'YR2020': 14687744162801.0,\n",
       " 'YR2021': 17820459508852.2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_results[\"CHN\"][\"TS_Y\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/work/climate-cooperation-competition/other_yamls/back_up_all/ZWE.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9944/3861387962.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/home/work/climate-cooperation-competition/other_yamls/back_up_all/{k}.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/work/climate-cooperation-competition/other_yamls/back_up_all/ZWE.yaml'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for k in raw_results:\n",
    "    with open(f\"/home/work/climate-cooperation-competition/other_yamls/back_up_all/{k}.yaml\", 'w') as f:\n",
    "        json.dump(raw_results[k], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge regions from data from small regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align the time series length of A, K and L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An output template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:58.680991Z",
     "start_time": "2022-05-24T13:51:58.670996Z"
    }
   },
   "outputs": [],
   "source": [
    "default = {\"_RICE_CONSTANT\":\n",
    "  {\"xgamma\": 0.3, # in CAP Eq 5 the capital elasticty\n",
    "\n",
    "  # A rice data\n",
    "  \"xA_0\": 0,\n",
    "  \"xg_A\": 0,\n",
    "  \"xdelta_A\": 0.0214976314392836,\n",
    "  # L\n",
    "  \"xL_0\": 1397.715000, # in POP population at the staring point\n",
    "  \"xL_a\": 1297.666000, # in POP the expected population at convergence\n",
    "  \"xl_g\": 0.04047275402855734, # in POP control the rate to converge\n",
    "  # K\n",
    "  \"xK_0\": 93.338152,\n",
    "  \"xa_1\": 0,\n",
    "  \"xa_2\": 0.00236 ,\n",
    "  \"xa_3\": 2,\n",
    "\n",
    "  # xsigma_0: 0.5201338309755572\n",
    "  \"xsigma_0\": 0.215}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the parameters of the dynamics from the timeseries gather the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:58.912990Z",
     "start_time": "2022-05-24T13:51:58.686996Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BWA', 'GAB', 'GNQ', 'MUS', 'NAM', 'ZAF', 'AGO', 'BEN', 'CIV', 'CMR', 'COG', 'COM', 'CPV', 'GHA', 'KEN', 'LSO', 'MRT', 'NGA', 'SEN', 'STP', 'SWZ', 'TZA', 'ZMB', 'ZWE', 'BDI', 'BFA', 'CAF', 'COD', 'ERI', 'ETH', 'GIN', 'GMB', 'GNB', 'LBR', 'MDG', 'MLI', 'MOZ', 'MWI', 'NER', 'RWA', 'SDN', 'SLE', 'SOM', 'SSD', 'TCD', 'TGO', 'UGA', 'SYC', 'MDV', 'BGD', 'BTN', 'IND', 'LKA', 'NPL', 'PAK', 'AFG', 'IRQ', 'JOR', 'LBN', 'LBY', 'DJI', 'DZA', 'EGY', 'IRN', 'MAR', 'PSE', 'TUN', 'SYR', 'YEM', 'ARE', 'BHR', 'ISR', 'KWT', 'MLT', 'OMN', 'QAT', 'SAU', 'ASM', 'CHN', 'FJI', 'MHL', 'MYS', 'THA', 'TON', 'TUV', 'FSM', 'IDN', 'KHM', 'KIR', 'LAO', 'MMR', 'MNG', 'PHL', 'PNG', 'SLB', 'TLS', 'VNM', 'VUT', 'WSM', 'AUS', 'BRN', 'GUM', 'HKG', 'JPN', 'KOR', 'MAC', 'MNP', 'NCL', 'NRU', 'NZL', 'PLW', 'PYF', 'SGP', 'TWN']\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.218649\n",
      "         Iterations: 91\n",
      "         Function evaluations: 166\n",
      "['ALB', 'ARM', 'AZE', 'BGR', 'BIH', 'BLR', 'GEO', 'KAZ', 'MDA', 'MKD', 'MNE', 'ROU', 'RUS', 'SRB', 'TKM', 'TUR', 'XKX', 'KGZ', 'TJK', 'UKR', 'UZB', 'AND', 'AUT', 'BEL', 'CHE', 'CHI', 'CYP', 'CZE', 'DEU', 'DNK', 'ESP', 'EST', 'FIN', 'FRA', 'FRO', 'GBR', 'GIB', 'GRC', 'GRL', 'HRV', 'HUN', 'IMN', 'IRL', 'ISL', 'ITA', 'LIE', 'LTU', 'LUX', 'LVA', 'MCO', 'NLD', 'NOR', 'POL', 'PRT', 'SMR', 'SVK', 'SVN', 'SWE']\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226181\n",
      "         Iterations: 91\n",
      "         Function evaluations: 181\n",
      "['BMU', 'CAN', 'USA', 'ARG', 'BRA', 'COL', 'CRI', 'CUB', 'DMA', 'DOM', 'ECU', 'GRD', 'GTM', 'GUY', 'JAM', 'LCA', 'MEX', 'PAN', 'PER', 'PRY', 'SUR', 'VCT', 'BLZ', 'BOL', 'HND', 'HTI', 'NIC', 'SLV', 'ABW', 'ATG', 'BHS', 'BRB', 'CHL', 'CUW', 'CYM', 'KNA', 'MAF', 'PRI', 'SXM', 'TCA', 'TTO', 'URY', 'VGB', 'VIR']\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.093233\n",
      "         Iterations: 85\n",
      "         Function evaluations: 165\n",
      "['BWA', 'GAB', 'GNQ', 'MUS', 'NAM', 'ZAF', 'AGO', 'BEN', 'CIV', 'CMR', 'COG', 'COM', 'CPV', 'GHA', 'KEN', 'LSO', 'MRT', 'NGA', 'SEN', 'STP', 'SWZ', 'TZA', 'ZMB', 'ZWE', 'BDI', 'BFA', 'CAF', 'COD', 'ERI', 'ETH', 'GIN', 'GMB', 'GNB', 'LBR', 'MDG', 'MLI', 'MOZ', 'MWI', 'NER', 'RWA', 'SDN', 'SLE', 'SOM', 'SSD', 'TCD', 'TGO', 'UGA', 'SYC', 'MDV', 'BGD', 'BTN', 'IND', 'LKA', 'NPL', 'PAK', 'AFG', 'IRQ', 'JOR', 'LBN', 'LBY', 'DJI', 'DZA', 'EGY', 'IRN', 'MAR', 'PSE', 'TUN', 'SYR', 'YEM', 'ARE', 'BHR', 'ISR', 'KWT', 'MLT', 'OMN', 'QAT', 'SAU', 'ASM', 'CHN', 'FJI', 'MHL', 'MYS', 'THA', 'TON', 'TUV', 'FSM', 'IDN', 'KHM', 'KIR', 'LAO', 'MMR', 'MNG', 'PHL', 'PNG', 'SLB', 'TLS', 'VNM', 'VUT', 'WSM', 'AUS', 'BRN', 'GUM', 'HKG', 'JPN', 'KOR', 'MAC', 'MNP', 'NCL', 'NRU', 'NZL', 'PLW', 'PYF', 'SGP', 'TWN', 'ALB', 'ARM', 'AZE', 'BGR', 'BIH', 'BLR', 'GEO', 'KAZ', 'MDA', 'MKD', 'MNE', 'ROU', 'RUS', 'SRB', 'TKM', 'TUR', 'XKX', 'KGZ', 'TJK', 'UKR', 'UZB', 'AND', 'AUT', 'BEL', 'CHE', 'CHI', 'CYP', 'CZE', 'DEU', 'DNK', 'ESP', 'EST', 'FIN', 'FRA', 'FRO', 'GBR', 'GIB', 'GRC', 'GRL', 'HRV', 'HUN', 'IMN', 'IRL', 'ISL', 'ITA', 'LIE', 'LTU', 'LUX', 'LVA', 'MCO', 'NLD', 'NOR', 'POL', 'PRT', 'SMR', 'SVK', 'SVN', 'SWE', 'BMU', 'CAN', 'USA', 'ARG', 'BRA', 'COL', 'CRI', 'CUB', 'DMA', 'DOM', 'ECU', 'GRD', 'GTM', 'GUY', 'JAM', 'LCA', 'MEX', 'PAN', 'PER', 'PRY', 'SUR', 'VCT', 'BLZ', 'BOL', 'HND', 'HTI', 'NIC', 'SLV', 'ABW', 'ATG', 'BHS', 'BRB', 'CHL', 'CUW', 'CYM', 'KNA', 'MAF', 'PRI', 'SXM', 'TCA', 'TTO', 'URY', 'VGB', 'VIR']\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.158644\n",
      "         Iterations: 87\n",
      "         Function evaluations: 164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "para_result = {k:{} for k in countryclass.keys()}\n",
    "for i in countryclass.keys():\n",
    "    print(countryclass[i])\n",
    "    a = merge_region_dict(packup_regions(raw_results, i, countryclass, exc_code, raw_results))\n",
    "    para_result[i][\"xl_g\"] = get_pop_lg(a[\"Ls\"], a[\"Las\"])\n",
    "    para_result[i][\"xL_a\"] = a[\"Las\"]/1_000_000\n",
    "    para_result[i][\"xL_0\"] = a[\"Ls\"][-1]/1_000_000\n",
    "    para_result[i][\"xg_A\"],para_result[i][\"xdelta_A\"] = get_gA_deltaA(a[\"As\"])\n",
    "    para_result[i][\"xA_0\"] = a[\"As\"][-1]\n",
    "    para_result[i][\"xK_0\"] = a[\"Ks\"][-1]/1_000_000_000_000\n",
    "    para_result[i][\"xsigma_0\"] = a[\"sigmas\"]/(1-0.05)\n",
    "    para_result[i][\"xtax\"] = a[\"taxs\"]\n",
    "    para_result[i][\"xmitigation_0\"] = a[\"mitigations\"]\n",
    "    para_result[i][\"xsaving_0\"] = a[\"savings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the \"rest of the world\" region and used the worldwide parameters for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:58.959490Z",
     "start_time": "2022-05-24T13:51:58.934489Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the number of population which is not covered\n",
    "popworldwide = list(df[df[\"economy\"]==\"WLD\"][df[\"series\"]==\"SP.POP.TOTL\"][\"YR2020\"])[0]\n",
    "popcovvered = sum([raw_results[x][\"TS_L\"][0][-1] for x in economy_region_list if x not in exc_code])\n",
    "popnotcovered = popworldwide - popcovvered\n",
    "# calculate the estimate worldwide convergence population\n",
    "covered_convergence_pop = sum([raw_results[x][\"La\"] for x in economy_region_list if x not in exc_code])\n",
    "not_covvered_convergence_pop = popnotcovered*covered_convergence_pop/popcovvered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:59.021488Z",
     "start_time": "2022-05-24T13:51:58.967494Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.158644\n",
      "         Iterations: 87\n",
      "         Function evaluations: 164\n"
     ]
    }
   ],
   "source": [
    "# check the worldwide properties\n",
    "i=0\n",
    "wld = {}\n",
    "a = merge_region_dict(packup_regions(raw_results, i, countryclass, exc_code, raw_results))\n",
    "wld[\"xl_g\"] = get_pop_lg(a[\"Ls\"], a[\"Las\"])\n",
    "wld[\"xL_a\"] = a[\"Las\"]/1_000_000\n",
    "wld[\"xL_0\"] = a[\"Ls\"][-1]/1_000_000\n",
    "wld[\"xg_A\"],wld[\"xdelta_A\"] = get_gA_deltaA(a[\"As\"])\n",
    "wld[\"xA_0\"] = a[\"As\"][-1]\n",
    "wld[\"xK_0\"] = a[\"Ks\"][-1]/1_000_000_000_000\n",
    "wld[\"xsigma_0\"] = a[\"sigmas\"]/(1-0.05)\n",
    "wld[\"xtax\"] = a[\"taxs\"]\n",
    "wld[\"xmitigation_0\"] = a[\"mitigations\"]\n",
    "wld[\"xsaving_0\"] = a[\"savings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:59.036491Z",
     "start_time": "2022-05-24T13:51:59.024487Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the rest of the world params\n",
    "rest_region = wld.copy()\n",
    "rest_region[\"xL_a\"] = not_covvered_convergence_pop/1_000_000\n",
    "rest_region[\"xL_0\"] = popnotcovered/1_000_000\n",
    "rest_region[\"xK_0\"] = popnotcovered*wld[\"xK_0\"]/popcovvered\n",
    "para_result[4] = rest_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_yaml_files(para_result, \"/home/work/climate-cooperation-competition/other_yamls/3_regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"csv_asset/3_import_2016.json\", \"r\") as json_file:\n",
    "    import_data_dict = json.load(json_file)\n",
    "with open(\"csv_asset/3_export_2016.json\", \"r\") as json_file:\n",
    "    export_data_dict = json.load(json_file)\n",
    "\n",
    "\n",
    "# Function to update a single YAML file with new data\n",
    "def update_yaml_file(file_path, data_im, data_ex):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as yaml_file:\n",
    "            current_data = yaml.safe_load(yaml_file) or {}\n",
    "    except FileNotFoundError:\n",
    "        current_data = {}\n",
    "\n",
    "    current_data[\"_RICE_CONSTANT\"][\"ximport\"] = data_im\n",
    "    current_data[\"_RICE_CONSTANT\"][\"xexport\"] = data_ex\n",
    "    with open(file_path, \"w\") as yaml_file:\n",
    "        yaml.dump(current_data, yaml_file, sort_keys=False)\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update the yaml files with import and export data\n",
    "[\n",
    "    update_yaml_file(\n",
    "        f\"/home/work/climate-cooperation-competition/other_yamls/3_regions/{i}.yml\",\n",
    "        import_data_dict[str(i)],\n",
    "        export_data_dict[str(i)],\n",
    "    )\n",
    "    for i in range(1, 4)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
